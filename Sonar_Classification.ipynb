{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sonar Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rangnguyen/deeplearning/blob/master/Sonar_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XRSR3kr3XxI",
        "colab_type": "text"
      },
      "source": [
        "In this homework, we will build a simple neural network model to identify whether rocks (0) or mock-mines (1) using the Sonar dataset. This is a binary classification problem.\n",
        "\n",
        "The dataset contains two csv files: sonar_train.csv (160x61) and sonar_test.csv (58x61). There are 60 input values and a single output value and the input values are standardized before being used in the network. The dataset is uploaded in Github and the skeleton code below provides the function to read these dataset.\n",
        "\n",
        "Your task is to build a baseline neural network model has two hidden layers: the first with 60 units and the second with 30. Stochastic gradient descent is used to train the model with a relatively low learning rate (=0.01) and momentum (=0.8). The binary cross entropy loss is used.\n",
        "\n",
        "Below is the skeleton for the homework:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wtEpYsvmbST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "import urllib.request as request\n",
        "import csv\n",
        "\n",
        "\n",
        "def read_data(url):\n",
        "  dataframe = read_csv(url, header=None)\n",
        "  dataset = dataframe.values\n",
        "  # split into input (X) and output (Y) variables\n",
        "  X = dataset[:,0:60].astype(float)\n",
        "  Y = dataset[:,60]\n",
        "  return X, Y\n",
        "\n",
        "# baseline\n",
        "def create_model():  \n",
        "  model = Sequential()\n",
        "  # YOUR CODE HERE\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  return model\n",
        "\n",
        "# load dataset\n",
        "url_train = 'https://raw.githubusercontent.com/rangnguyen/deeplearning/master/hw1/sonar_train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/rangnguyen/deeplearning/master/hw1/sonar_test.csv'\n",
        "\n",
        "X_train, Y_train = read_data(url_train)\n",
        "X_test, Y_test = read_data(url_test)\n",
        "\n",
        "\n",
        " \n",
        "model = create_model()\n",
        "model.fit(X_train, Y_train, epochs=1000)\n",
        "score, acc = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(\"Test accuracy: %.2f%%\" % (acc))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}